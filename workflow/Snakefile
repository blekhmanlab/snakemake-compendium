from datetime import datetime

configfile: "config/config.yaml"

onstart:
    shell('touch running.txt')
onsuccess:
    shell('rm running.txt')
    shell(f"sbatch --job-name=forward -o logs/{int(round(datetime.now().timestamp()))}.log --chdir={config['cmanager_path']} run_autoforward.slurm")
onerror:
    shell('rm running.txt')

with open('SraAccList.txt', 'r') as file:
    samples = file.read().splitlines()

shell.executable("/bin/sh") # sra-tools container doesn't have bash

rule all:
    input:
        'summary.tsv', 'ASV.tsv', 'ASVs.fa', 'ASVs_counts.tsv'

rule sra_prefetch:
    input:
        'SraAccList.txt'
    output:
        temp(expand('{sample}/{sample}.sra',sample=samples))
    threads: 1
    retries: 3
    resources:
        mem_mb=500,
        runtime=480
    shell:
        f"singularity exec --bind {config['cmanager_path']} {config['resources_path']}sra-tools_3.0.1.sif prefetch --option-file SraAccList.txt"

rule sra_to_fastq:
    input:
        '{sample}/{sample}.sra'
    output:
        'fastq/{sample}.fastq'
    threads: 4
    resources:
        mem_mb=2000,
        runtime=480
    shell:
        """
        singularity exec --bind {config[cmanager_path]} {config[resources_path]}sra-tools_3.0.1.sif fasterq-dump --skip-technical --mem 1GB --threads 4 --split-files -O fastq/ {wildcards.sample} &&
            [ ! -f fastq/{wildcards.sample}_1.fastq ] || mv fastq/{wildcards.sample}_1.fastq fastq/{wildcards.sample}.fastq
        """

def get_mem_mb_filter(wildcards, attempt):
    tiers = [16, 24, 48, 64] # in gigabytes
    return tiers[attempt-1] * 1000

rule filter:
    retries: 3
    input:
        expand('fastq/{sample}.fastq', sample=samples)
    output:
        expand('intermediate/{sample}.R1.filtered.fastq.gz', sample=samples),
        'filtered_out.rds'
    threads: 8
    retries: 1
    resources:
        mem_mb=get_mem_mb_filter,
        runtime=1440
    shell:
        f"singularity exec --bind {config['cmanager_path']} {config['resources_path']}dada2_1260a.sif Rscript scripts/filter.R"

def get_mem_mb_errormodel(wildcards, attempt):
    tiers = [16, 32, 64, 96]
    return tiers[attempt-1] * 1000

# NOTE: We don't calculate the error models in parallel because it's needlessly
# complicated to tell Snakemake to conditionally require the reverse model
rule errormodel:
    input:
        expand('intermediate/{sample}.R1.filtered.fastq.gz', sample=samples),
        'filtered_out.rds'
    output:
        'err_forward_reads.rds',
        'forward_error_model.pdf'
    threads: 8
    retries: 1
    resources:
        mem_mb=get_mem_mb_errormodel,
        runtime=1440
    shell:
        f"singularity exec --bind {config['cmanager_path']} {config['resources_path']}dada2_1260a.sif Rscript scripts/error_models.R"

def get_mem_mb_dada(wildcards, attempt):
    if len(samples) < 50:
        tiers = [16, 32, 48, 56]
    elif len(samples) < 150:
        tiers = [32, 48, 56, 72]
    elif len(samples) < 400:
        tiers = [48, 64, 96, 96]
    else:
        tiers = [64, 80, 96, 118]
    return(tiers[attempt-1] * 1000)

def get_runtime_dada(wildcards, attempt):
    tiers = [48, 64, 96, 96] # hours
    return(tiers[attempt-1] * 60)

rule make_asv_table:
    input:
        expand('intermediate/{sample}.R1.filtered.fastq.gz', sample=samples),
        'err_forward_reads.rds'
    output:
        'summary.tsv', 'ASV.tsv', 'ASVs.fa', 'ASVs_counts.tsv'
    threads: 8
    retries: 3
    resources:
        mem_mb=get_mem_mb_dada,
        runtime=get_runtime_dada
    shell:
        f"singularity exec --bind {config['cmanager_path']} {config['resources_path']}dada2_1260a.sif Rscript scripts/generate_asvs.R"
